{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Template"
      ],
      "metadata": {
        "id": "E254-OD_nSRJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhSyhfEy4XSD"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHf1dAVKAcZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f2c28f-8a44-415d-a990-fe05be82eeb6"
      },
      "source": [
        "env = gym.make('FrozenLake-v1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-6usoQHAmqh",
        "outputId": "1c55a0c5-2891-4f80-effe-3b383c8f9028"
      },
      "source": [
        "env.P[0][3] # Transition model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.3333333333333333, 1, 0.0, False),\n",
              " (0.3333333333333333, 0, 0.0, False),\n",
              " (0.3333333333333333, 0, 0.0, False)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh7Su0h0AqQz",
        "outputId": "47accafe-4ece-498f-aa93-61793fc64e08"
      },
      "source": [
        "env.observation_space.n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ68w5bpBScC",
        "outputId": "dc65fe3c-222d-4ceb-ed48-695e1a0add83"
      },
      "source": [
        "env.action_space.n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWLnvY7VBvIZ"
      },
      "source": [
        "def play(env, policy, render=False):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = policy[state]\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        steps += 1\n",
        "        if render:\n",
        "            env.render()\n",
        "            time.sleep(0.2)\n",
        "            if not done:\n",
        "                display.clear_output(wait=True)\n",
        "        state = next_state\n",
        "\n",
        "    return (total_reward, steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcuDDx6rC5YE",
        "outputId": "4b8ec0f5-2cd7-4ea2-b187-4b0488cc0c57"
      },
      "source": [
        "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "play(env, policy_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdyjjtGZC9NX",
        "outputId": "650879c7-80b2-4b71-d88f-3a63f6ec95a3"
      },
      "source": [
        "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
        "play(env, policy_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt0VhyMuDasc",
        "outputId": "b3e481ee-8fe5-4940-8199-b241ef4a7006"
      },
      "source": [
        "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
        "play(env, policy_2, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp6qhRFJDxWR",
        "outputId": "e8ca33b5-869c-4ee3-cda3-ce166f76fa07"
      },
      "source": [
        "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
        "play(env, policy_3, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU8Q1qMxD6Po"
      },
      "source": [
        "def play_multiple_times(env, policy, max_episodes):\n",
        "    success = 0\n",
        "    list_of_steps = []\n",
        "    for i in range(max_episodes):\n",
        "        total_reward, steps = play(env, policy)\n",
        "\n",
        "        if total_reward > 0:\n",
        "            success += 1\n",
        "            list_of_steps.append(steps)\n",
        "\n",
        "    print(f'Number of successes: {success}/{max_episodes}')\n",
        "    print(f'Average number of steps: {np.mean(list_of_steps)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G427z17PEmjQ",
        "outputId": "fa8d4fd5-969b-44d3-e433-c9777731c984"
      },
      "source": [
        "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "play_multiple_times(env, policy_0, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 0/1000\n",
            "Average number of steps: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1bkhaFdDmj_",
        "outputId": "e000334e-2218-4855-fc34-f636bf69bb40"
      },
      "source": [
        "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
        "play_multiple_times(env, policy_1, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 60/1000\n",
            "Average number of steps: 11.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZYhsb_VEtuR",
        "outputId": "ea5a4c0b-dee0-4006-f764-f72d568af1ed"
      },
      "source": [
        "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
        "play_multiple_times(env, policy_2, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 107/1000\n",
            "Average number of steps: 14.280373831775702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvvHdMesEzTH",
        "outputId": "cacc960e-7299-46c3-cb0f-1ca265b9e6d9"
      },
      "source": [
        "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
        "play_multiple_times(env, policy_3, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 738/1000\n",
            "Average number of steps: 37.4579945799458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSomNpxJE5lP"
      },
      "source": [
        "def policy_evaluation(env, policy, max_iters=500, gamma=0.9):\n",
        "    # Initialize the values of all states to be 0\n",
        "    v_values = np.zeros(env.observation_space.n)\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        prev_v_values = np.copy(v_values)\n",
        "\n",
        "        # Update the value of each state\n",
        "        for state in range(env.observation_space.n):\n",
        "            action = policy[state]\n",
        "\n",
        "            # Compute the q-value of the action\n",
        "            q_value = 0\n",
        "            for prob, next_state, reward, done in env.P[state][action]:\n",
        "                q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
        "\n",
        "            v_values[state] = q_value # update v-value\n",
        "        \n",
        "        # Check convergence\n",
        "        if np.all(np.isclose(v_values, prev_v_values)):\n",
        "            print(f'Converged at {i}-th iteration.')\n",
        "            break\n",
        "    \n",
        "    return v_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7IhqEOgGkQX",
        "outputId": "987bdf72-ce6e-4759-c9e4-cac25509eec7"
      },
      "source": [
        "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "v_values_0 = policy_evaluation(env, policy_0)\n",
        "print(v_values_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 0-th iteration.\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMjJKI3GGrsN",
        "outputId": "e87e015e-707f-4238-d48a-b75d87eced59"
      },
      "source": [
        "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
        "v_values_1 = policy_evaluation(env, policy_1)\n",
        "print(v_values_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 48-th iteration.\n",
            "[0.01904157 0.01519815 0.03161906 0.02371389 0.02538879 0.\n",
            " 0.06648515 0.         0.05924054 0.13822794 0.18999823 0.\n",
            " 0.         0.21152109 0.56684236 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-26M77nEfcV",
        "outputId": "f0bfeb47-805a-4ac7-ce33-d31f0eac1bcb"
      },
      "source": [
        "np.all(v_values_1 >= v_values_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l49O1N8QG0S2",
        "outputId": "2227767e-bece-4b62-9703-952e142190f4"
      },
      "source": [
        "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
        "v_values_2 = policy_evaluation(env, policy_2)\n",
        "print(v_values_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 53-th iteration.\n",
            "[0.02889625 0.01951972 0.03616977 0.0271268  0.04790519 0.\n",
            " 0.07391985 0.         0.08288277 0.19339319 0.21022995 0.\n",
            " 0.         0.35153135 0.62684674 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22pRvreGE3Yt",
        "outputId": "60e9e572-4db6-4335-d325-17082e92874f"
      },
      "source": [
        "np.all(v_values_2 >= v_values_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTYYFq6BEXDd",
        "outputId": "c3c544c8-fe03-462a-9ae1-9e8b71a531cf"
      },
      "source": [
        "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
        "v_values_3 = policy_evaluation(env, policy_3)\n",
        "print(v_values_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 80-th iteration.\n",
            "[0.06888666 0.06141097 0.07440714 0.05580443 0.09185068 0.\n",
            " 0.11220679 0.         0.14543323 0.24749485 0.29961611 0.\n",
            " 0.         0.37993438 0.63901935 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcEfU3NYE7xN",
        "outputId": "89bc8312-b38c-4e1d-a8fc-45a0b4c5a683"
      },
      "source": [
        "np.all(v_values_3 >= v_values_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh4akjMSHJBF"
      },
      "source": [
        "def value_iteration(env, max_iters=500, gamma=0.9):\n",
        "    # initialize\n",
        "    v_values = np.zeros(env.observation_space.n)\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        prev_v_values = np.copy(v_values)\n",
        "\n",
        "        # update the v-value for each state\n",
        "        for state in range(env.observation_space.n):\n",
        "            q_values = []\n",
        "            \n",
        "            # compute the q-value for each action that we can perform at the state\n",
        "            for action in range(env.action_space.n):\n",
        "                q_value = 0\n",
        "                # loop through each possible outcome\n",
        "                for prob, next_state, reward, done in env.P[state][action]:\n",
        "                    q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
        "                \n",
        "                q_values.append(q_value)\n",
        "            \n",
        "            # select the max q-values\n",
        "            best_action = np.argmax(q_values)\n",
        "            v_values[state] = q_values[best_action]\n",
        "        \n",
        "        # check convergence\n",
        "        if np.all(np.isclose(v_values, prev_v_values)):\n",
        "            print(f'Converged at {i}-th iteration.')\n",
        "            break\n",
        "\n",
        "    return v_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8xAljw7VuMP",
        "outputId": "308044f3-10bc-4e8f-beb7-0615b4b90afe"
      },
      "source": [
        "optimal_v_values = value_iteration(env, max_iters=500, gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 79-th iteration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7g9VA3lV2WW",
        "outputId": "ea9c4343-f50c-499a-8446-d062f94b50cc"
      },
      "source": [
        "optimal_v_values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.06888615, 0.06141054, 0.07440682, 0.05580409, 0.09185022,\n",
              "       0.        , 0.11220663, 0.        , 0.14543286, 0.2474946 ,\n",
              "       0.29961593, 0.        , 0.        , 0.3799342 , 0.63901926,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb0an7gaV39e"
      },
      "source": [
        "def policy_extraction(env, v_values, gamma=0.9):\n",
        "    # initialize\n",
        "    policy = np.zeros(env.observation_space.n, dtype=int)\n",
        "\n",
        "    # loop through each state in the environment\n",
        "    for state in range(env.observation_space.n):\n",
        "        q_values = []\n",
        "        # loop through each action\n",
        "        for action in range(env.action_space.n):\n",
        "            q_value = 0\n",
        "            # loop each possible outcome\n",
        "            for prob, next_state, reward, done in env.P[state][action]:\n",
        "                q_value += prob * (reward + gamma * v_values[next_state])\n",
        "            \n",
        "            q_values.append(q_value)\n",
        "        \n",
        "        # select the best action\n",
        "        best_action = np.argmax(q_values)\n",
        "        policy[state] = best_action\n",
        "    \n",
        "    return policy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TGCF4G7XErH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb9b36f-0165-454d-bc29-82c0edc11dc0"
      },
      "source": [
        "optimal_policy = policy_extraction(env, optimal_v_values, gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-9e926206ddb9>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  policy = np.zeros(env.observation_space.n, dtype=np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-m4ZqWZXKqG",
        "outputId": "d4381ac5-20b8-4415-fe80-dd0330a874c7"
      },
      "source": [
        "optimal_policy\n",
        "play_multiple_times(env, optimal_policy, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 735/1000\n",
            "Average number of steps: 37.97551020408163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZY-vM9YXMRX",
        "outputId": "a588a162-2ec4-4d03-ef08-ac1b419d0df4"
      },
      "source": [
        "play_multiple_times(env, policy_1, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 42/1000\n",
            "Average number of steps: 11.619047619047619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My code"
      ],
      "metadata": {
        "id": "dAx_Iji2nXfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value_iteration_runtime = []\n",
        "policy_iteration_runtime = []"
      ],
      "metadata": {
        "id": "y3vWs4Czslsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Policy Iteration"
      ],
      "metadata": {
        "id": "VAPxs1kunkMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_iteration(env, max_iters=500, gamma=0.9):\n",
        "  # Policy Initialize\n",
        "  pi_values = np.zeros(env.observation_space.n)\n",
        "\n",
        "  for i in range(max_iters):\n",
        "    prev_pi_values = np.copy(pi_values)\n",
        "\n",
        "    # Policy Evaluation \n",
        "    v_values = policy_evaluation(env, pi_values)\n",
        "\n",
        "    # Policy Improvement\n",
        "    pi_values = policy_extraction(env, v_values, gamma)\n",
        "    \n",
        "    # Check exit condition\n",
        "    if np.array_equal(pi_values, prev_pi_values):\n",
        "      print(f'Action converged at {i}-th iteration.')\n",
        "      break\n",
        "\n",
        "  return pi_values"
      ],
      "metadata": {
        "id": "1khXEfc9WPbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FrozenLake-v1\n"
      ],
      "metadata": {
        "id": "4Qcv358Cnqjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create environment\n",
        "env = gym.make('FrozenLake-v1')"
      ],
      "metadata": {
        "id": "9tyJF4tOn8-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Value Iteration"
      ],
      "metadata": {
        "id": "mVSU_0qGoV9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "# Value Iteration\n",
        "optimal_v_values = value_iteration(env, max_iters=500, gamma=0.9)\n",
        "\n",
        "# Policy Extraction\n",
        "optimal_pi_values = policy_extraction(env, optimal_v_values, gamma=0.9)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# Test Policy\n",
        "play_multiple_times(env, optimal_pi_values, max_episodes=1000)\n",
        "\n",
        "value_iteration_runtime.append(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuIPQBwkoVhV",
        "outputId": "af085c0a-f653-454c-bac2-1948021f98ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 79-th iteration.\n",
            "Number of successes: 720/1000\n",
            "Average number of steps: 37.05555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Policy Iteration"
      ],
      "metadata": {
        "id": "ORYWgZa3obuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "# Policy Iteration\n",
        "optimal_pi_values = policy_iteration(env, max_iters=500, gamma=0.9)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# Test Policy\n",
        "play_multiple_times(env, optimal_pi_values, max_episodes=1000)\n",
        "\n",
        "policy_iteration_runtime.append(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGLqpfIfod3c",
        "outputId": "ee519829-cc17-43e8-c63c-ef0c0d51857f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 0-th iteration.\n",
            "Converged at 23-th iteration.\n",
            "Converged at 59-th iteration.\n",
            "Converged at 62-th iteration.\n",
            "Converged at 79-th iteration.\n",
            "Converged at 80-th iteration.\n",
            "Action converged at 5-th iteration.\n",
            "Number of successes: 735/1000\n",
            "Average number of steps: 37.06666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FrozenLake8x8-v1"
      ],
      "metadata": {
        "id": "gPL0OJCGn2gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create environment\n",
        "env = gym.make('FrozenLake8x8-v1')"
      ],
      "metadata": {
        "id": "_iVL-dVLtOui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Value Iteration"
      ],
      "metadata": {
        "id": "kM-GScgDtOum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "# Value Iteration\n",
        "optimal_v_values = value_iteration(env, max_iters=500, gamma=0.9)\n",
        "\n",
        "# Policy Extraction\n",
        "optimal_pi_values = policy_extraction(env, optimal_v_values, gamma=0.9)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# Test Policy\n",
        "play_multiple_times(env, optimal_pi_values, max_episodes=1000)\n",
        "\n",
        "value_iteration_runtime.append(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b650475-eca6-4e52-9cfe-0c0e08b62555",
        "id": "Z5ZBaBhutOum"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 117-th iteration.\n",
            "Number of successes: 728/1000\n",
            "Average number of steps: 71.81318681318682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Policy Iteration"
      ],
      "metadata": {
        "id": "9izPCQj5tOun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "# Policy Iteration\n",
        "optimal_pi_values = policy_iteration(env, max_iters=500, gamma=0.9)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# Test Policy\n",
        "play_multiple_times(env, optimal_pi_values, max_episodes=1000)\n",
        "\n",
        "policy_iteration_runtime.append(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1c59ed-7aa5-4f2f-bca6-eb419ab12386",
        "id": "df_1hc68tOuo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 27-th iteration.\n",
            "Converged at 91-th iteration.\n",
            "Converged at 92-th iteration.\n",
            "Converged at 86-th iteration.\n",
            "Converged at 90-th iteration.\n",
            "Converged at 92-th iteration.\n",
            "Converged at 95-th iteration.\n",
            "Converged at 100-th iteration.\n",
            "Converged at 112-th iteration.\n",
            "Converged at 117-th iteration.\n",
            "Action converged at 9-th iteration.\n",
            "Number of successes: 749/1000\n",
            "Average number of steps: 73.6502002670227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taxi-v3"
      ],
      "metadata": {
        "id": "OJ7-freRn5b3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create environment\n",
        "env = gym.make('Taxi-v3')"
      ],
      "metadata": {
        "id": "MfGU4dl9tdWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Value Iteration"
      ],
      "metadata": {
        "id": "ShhqTZ62tdXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "# Value Iteration\n",
        "optimal_v_values = value_iteration(env, max_iters=500, gamma=0.9)\n",
        "\n",
        "# Policy Extraction\n",
        "optimal_pi_values = policy_extraction(env, optimal_v_values, gamma=0.9)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# Test Policy\n",
        "play_multiple_times(env, optimal_pi_values, max_episodes=1000)\n",
        "\n",
        "value_iteration_runtime.append(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca11e37-d1cc-4664-88f3-b884db78d8aa",
        "id": "SVCPkLIUtdXG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 116-th iteration.\n",
            "Number of successes: 1000/1000\n",
            "Average number of steps: 13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Policy Iteration"
      ],
      "metadata": {
        "id": "DVP0VG0WtdXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "# Policy Iteration\n",
        "optimal_pi_values = policy_iteration(env, max_iters=500, gamma=0.9)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# Test Policy\n",
        "play_multiple_times(env, optimal_pi_values, max_episodes=1000)\n",
        "\n",
        "policy_iteration_runtime.append(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0621dc-b52d-4bba-cbdd-befceede01a6",
        "id": "VRhKnwqLtdXI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 88-th iteration.\n",
            "Converged at 97-th iteration.\n",
            "Converged at 100-th iteration.\n",
            "Converged at 101-th iteration.\n",
            "Converged at 102-th iteration.\n",
            "Converged at 103-th iteration.\n",
            "Converged at 106-th iteration.\n",
            "Converged at 109-th iteration.\n",
            "Converged at 110-th iteration.\n",
            "Converged at 111-th iteration.\n",
            "Converged at 112-th iteration.\n",
            "Converged at 115-th iteration.\n",
            "Converged at 116-th iteration.\n",
            "Converged at 116-th iteration.\n",
            "Converged at 116-th iteration.\n",
            "Converged at 116-th iteration.\n",
            "Converged at 116-th iteration.\n",
            "Action converged at 16-th iteration.\n",
            "Number of successes: 1000/1000\n",
            "Average number of steps: 12.998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "PNhRAzdxtmck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trong các toy games, thuật toán Value Iteration cho ra kết quả nhanh hơn (trung bình thời gian chạy) ~2.41 lần. \n",
        "# Đặc biệt, với env Taxi-v3, Value Iteration chạy nhanh hơn Policy Iteration đến ~3 lần! \n",
        "\n",
        "# Average time of Value Iteration\n",
        "print(f\"Average runtime of Value Iteration: {np.average(value_iteration_runtime)} sec\")  # 0.947259267171224s\n",
        "\n",
        "# Average time of Policy Iteration  \n",
        "print(f\"Average runtime of Policy Iteration: {np.average(policy_iteration_runtime)} sec\")  # 2.2854963143666587s\n",
        "\n",
        "# Tuy nhiên, Policy Iteration tốn ít bước (iteration) hơn để đến được điểm hội tụ \n",
        "# Game: <Policy Iteration> -- <Value Iteration>\n",
        "# FrozenLake-v1:     5 -- 79\n",
        "# FrozenLake8x8-v1:  9 -- 111\n",
        "# Taxi-v3:          16 -- 116\n",
        "\n",
        "# Mặc dù mất ít lần lặp hơn để hội tụ, tuy nhiên, do Policy Iteration phải thực hiện đánh giá chiến thuật (policy_extraction) trên nhiều chiến thuật khác nhau.\n",
        "# Nên Policy Iteration mất thời gian lâu hơn để cho ra kết quả. \n",
        "\n",
        "# Cả hai thuật toán đều đảm bảo hội tụ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXrgiL4qtg1e",
        "outputId": "ea159b15-69d9-4d0a-f1ed-192b4dad4df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average runtime of Value Iteration: 0.947259267171224 sec\n",
            "Average runtime of Policy Iteration: 2.2854963143666587 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value_iteration_runtime"
      ],
      "metadata": {
        "id": "nF1Y3WsNTZbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6e573c-e644-481b-f236-cea96fba9363"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04501223564147949, 0.27802515029907227, 2.51874041557312]"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "policy_iteration_runtime"
      ],
      "metadata": {
        "id": "ny36FwUSXQG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d557d1e0-3978-4f4f-e09a-10e82e16ff09"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05892753601074219, 0.40698862075805664, 6.390572786331177]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    }
  ]
}